Embedded smartphone sensors are becoming increasingly sophisticated and can be incorporated in various domains such as health care, fitness care, skill assessment, and personal assistant to support the independent living. Furthermore, these sensors can be used to monitor daily life physical activities. In this paper, we propose a framework for activity recognition using raw readings of the combination of fused smartphone sensors: accelerometer, gyroscope, magnetometer and Google Fit activity tracking module by applying a Deep Recurrent Neural Network (DRNN). We analyze several combination of architectures to find the optimal parameter values. We use a large training dataset consisting of five activity classes from ten participants to investigate various combination and parameters. To implement our system, we make an android application that runs in the background and collects data from smartphone hardware sensors fused with Google Fit API. We fused sensors and Google Fit API in order to strengthen the recognition process. We show that in general, fused modules make the activity recognition process more reliable instead of using only sensors readings. This study suggests that this type of fused technique is signification for activity recognition.
